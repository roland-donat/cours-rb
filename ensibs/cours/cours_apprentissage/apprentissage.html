<!DOCTYPE html>
<html lang="fr">
<head>
<meta charset="utf-8"/>
<title>Modélisation stochastique et approche bayésienne  <br> <br> <br> <font size="10">Apprentissage automatique des lois de probabilité conditionnelles</font></title>
<meta name="author" content="Roland Donat"/>
<meta name="description" content=""/>
<meta name="keywords" content=""/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js/dist/reveal.css"/>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js/dist/theme/white.css" id="theme"/>

<link rel="stylesheet" href="https://roland-donat.github.io/ubs/Charte_graphique/ensibs/ensibs_reveal.css"/>

<!-- If the query includes 'print-pdf', include the PDF print sheet -->
<script>
    if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = 'https://cdn.jsdelivr.net/npm/reveal.js/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    }
</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
TeX: {
Macros: {
pa: ["\\text{pa}"],
Pa: ["\\text{Pa}"],
lrpar: ["\\left( #1 \\right)", 1],
lrPar: ["\\left( #1 \\right)", 1],
lrbrack: ["[ #1 ]", 1],
lrBrack: ["\\left[ #1 \\right]", 1],
set: ["\\left\\lbrace #1 \\right\\rbrace", 1],
Prob: ["P"],
inter: ["\\cap"],
union: ["\\cup"],
Dom: ["\\text{Dom}"],
mbf: ["\\boldsymbol{#1}", 1],
argmin: ["\\underset{#1}{\arg\min}~", 1],
argmax: ["\\underset{#1}{\arg\max}~", 1],
mathbfcal: ["\\boldsymbol{\\mathcal{#1}}", 1],
sm: ["\\setminus"],
}
}
});
</script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide" data-background="https://roland-donat.github.io/ubs/Charte_graphique/ensibs/ensibs-ppt-couv.jpg"><h1 class="title">Modélisation stochastique et approche bayésienne  <br> <br> <br> <font size="10">Apprentissage automatique des lois de probabilité conditionnelles</font></h1><p class="subtitle"></p>
<h2 class="author">Roland Donat</h2><h2 class="date"> <br>Spécialité Cyber Data</h2>
</section>
<section id="sec-table-of-contents"><div id="table-of-contents" role="doc-toc">
<h2>Table des matières</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#/slide-org6577ad6">Objectifs de la séance</a></li>
<li><a href="#/slide-org1df10f7">Introduction</a></li>
<li><a href="#/slide-orge5ebf15">Rappels statistiques</a></li>
<li><a href="#/slide-orgd25ebe1">Apprentissage des LPC - Données complètes</a></li>
<li><a href="#/slide-org8a0bd0a">Apprentissage des LPC - Données incomplètes</a></li>
<li><a href="#/slide-org28c43be">Résumé de la séance</a></li>
<li><a href="#/slide-orgb2b4606">Bibliographie</a></li>
</ul>
</div>
</div>
</section>


<section>
<section id="slide-org6577ad6">
<h2 id="org6577ad6">Objectifs de la séance</h2>
<div class="column" style="float:left; width: 50%">

<ul>
<li>Comprendre les problématiques liées à la construction pratique d'un réseau bayésien</li>
<li>Estimer automatiquement les lois de probabilité conditionnelles (LPC) à partir de données
observées sur le phénomène étudié</li>

</ul>

</div>

<div class="column" style="float:right; width: 50%">


<div id="orgba615ce" class="figure">
<p><img src="./fig/objectives.png" alt="Objectives" width="100%" />
</p>
</div>

</div>

</section>
</section>
<section>
<section id="slide-org1df10f7">
<h2 id="org1df10f7">Introduction</h2>

<div id="org475a4cc" class="figure">
<p><img src="./fig/machine_learning.png" alt="Inférence" width="70%" />
</p>
</div>


</section>
</section>
<section>
<section id="slide-org9947334">
<h3 id="org9947334">Problématique</h3>
<div class="block-definition" id="orgd188ad9">
<p>
<h4>Objectif</h4>
</p>

<ul>
<li>Modéliser un phénomène aléatoire impliquant différentes variables \(X_{1}, \ldots, X_{D}\)</li>
<li>Utiliser un réseau bayésien afin de représenter au mieux les relations entre les variables</li>

</ul>

</div>

<div class="block-definition" id="org85bf90e">
<p>
<h4>Problèmes</h4>
</p>

<ul>
<li>Comment déterminer la structure du réseau bayésien (i.e. le graphe)?</li>
<li>Comment estimer les lois de probabilité conditionnelles (LPC) \(P(X_{d}|\text{pa}(X_{d})),~ d = 1,
  \ldots, D\) ?</li>

</ul>

</div>

<div class="block-example" id="org9d38687">
<p>
<h4>Approches envisageables</h4>
</p>

<ul>
<li>Approche par expertise : utilisation d'avis d'experts et connaissances métiers</li>
<li>Approche statistique : utilisation de bases de données (contenant éventuellement des
informations incomplètes)</li>
<li>Approche mixte : expertise + bases de données</li>

</ul>

</div>

</section>
<section id="slide-org205756d">
<h4 id="org205756d">Problématique</h4>
<p>
<div class="slidesubtitle">Exemple : Vente d'un livret</div>
</p>


<div id="org8f3a5cd" class="figure">
<p><img src="./fig/rb_vente_var.png" alt="RB vente" width="95%" />
</p>
</div>

</section>
<section id="slide-org25812aa">
<h4 id="org25812aa">Problématique</h4>
<p>
<div class="slidesubtitle">Apprentissage de la structure</div>
</p>


<div id="org4234793" class="figure">
<p><img src="./fig/rb_vente_graphe_app.png" alt="RB vente" width="95%" />
</p>
</div>


</section>
<section id="slide-org5fd86ba">
<h4 id="org5fd86ba">Problématique</h4>
<p>
<div class="slidesubtitle">Apprentissage des LPC (structure fixée)</div>
</p>


<div id="org1a554fc" class="figure">
<p><img src="./fig/rb_vente_lpc_app.png" alt="RB vente" width="95%" />
</p>
</div>


</section>
<section id="slide-org67f839a">
<h4 id="org67f839a">Problématique</h4>
<p>
<div class="slidesubtitle">Apprentissage complet du réseau bayésien</div>
</p>


<div id="org3c237f5" class="figure">
<p><img src="./fig/rb_vente_graphe_lpc_app.png" alt="RB vente" width="95%" />
</p>
</div>


</section>
</section>
<section>
<section id="slide-orge14dde7">
<h3 id="orge14dde7">Construction par expertise</h3>
<p>
<div class="slidesubtitle">Acquisition de l'information</div>
</p>

<div class="block-definition" id="orga03a216">
<p>
<h4>Acquisition de l'information</h4>
</p>

<ul>
<li>Trouver des personnes expertes fiables et coopératives</li>
<li>Familiariser ces personnes à la notion de probabilité</li>
<li>Tenir compte de leurs biais éventuels (souvent inconscients)</li>
<li>Utiliser un outil pour faciliter le recueil des informations</li>
<li>Exemple : échelle de probabilité :</li>

</ul>


<div id="org1087694" class="figure">
<p><img src="https://roland-donat.github.io/cours-rb/stid_intro/fig/echelle_prob.png" alt="Echelle prob" width="90%" />
</p>
</div>

<p>
 <br>
</p>

</div>



</section>
<section id="slide-org4bda0fd">
<h4 id="org4bda0fd">Construction par expertise</h4>
<p>
<div class="slidesubtitle">Attention au connexions convergentes (V-structures)</div>
</p>

<div class="block-alert" id="orgc50764f">
<p>
<h4>Problème</h4>
</p>

<ul>
<li>L'expertise métier permet en général de construire des RB fidèles à la réalité opérationnelle</li>
<li>En revanche, l'humain a intuitivement tendance à introduire des connexions convergentes
<ul>
<li>Exemple : Soit \(Y\) un phénomène à expliquer et \(X_{1}, \ldots, X_{D}\), \(D\) facteurs explicatifs possibles</li>
<li>Structure naturelle : \(X_{1} \to Y, \ldots, X_{D} \to Y\)</li>
<li>Risque d'explosion combinatoire : Définir \(P(Y|X_{1},\ldots,X_{D})\) nécessite \(2^{D}\) valeurs
dans le cas où les variables sont binaires</li>

</ul></li>

</ul>

</div>

<div class="fragment (appear) block-example" id="org4250ed5">
<p>
<h4>Solutions possibles</h4>
</p>

<ul>
<li>Inverser les flèches et utiliser une structure naïve : \(Y \to X_{1}, \ldots, Y \to X_{D}\) en
assumant les simplifications induites</li>
<li>Introduction d'un modèle de LPC particulier, e.g. modèle OU-bruité</li>

</ul>

</div>

</section>
</section>
<section>
<section id="slide-orge5ebf15">
<h2 id="orge5ebf15">Rappels statistiques</h2>

<div id="org500a190" class="figure">
<p><img src="./fig/stats.png" alt="Inférence" width="70%" />
</p>
</div>

</section>
</section>
<section>
<section id="slide-org562cea3">
<h3 id="org562cea3">Rappels statistiques</h3>
<p>
<div class="slidesubtitle">Tableau de données</div>
</p>

<div class="block-definition" id="org2dbce17">
<p>
<h4>Caractéristiques des données</h4>
</p>

<ul>
<li>Un tableau de données, notée \(\mathcal{D}\), est un ensemble de \(N\)
observations/individus/exemples caractérisés par \(D\) variables</li>
<li><p>
Formellement, un tableau de données peut se mettre sous la forme d'une matrice :
</p>
<div>
\begin{equation*}
\mathcal{D} =
\lrBrack{
\begin{array}{ccccc}
x_{1,1} & \ldots & x_{1,d} & \ldots & x_{1,D} \\
\vdots  &        & \vdots  &        & \vdots \\
x_{n,1} & \ldots & x_{n,d} & \ldots & x_{n,D} \\
\vdots  &        & \vdots  &        & \vdots \\
x_{N,1} & \ldots & x_{N,d} & \ldots & x_{N,D} \\
\end{array}
}
\end{equation*}

</div>
<ul>
<li>Le vecteur colonne \(\mbf{x}_{\cdot, d} = \lrPar{x_{1,d}, \ldots, x_{n,d}, \ldots, x_{N,d}}\)
représente toutes les observations de la variable \(d\)</li>
<li>Le vecteur ligne \(\mbf{x}_{n, \cdot} = \lrPar{x_{n,1}, \ldots, x_{n,d}, \ldots, x_{n,D}}\)
représente la $n$-ème observation de la BdD</li>

</ul></li>

</ul>

</div>


</section>
<section id="slide-org860f3ac">
<h4 id="org860f3ac">Rappels statistiques</h4>
<p>
<div class="slidesubtitle">Tableau de données</div>
</p>

<div class="column" style="float:left; width: 45%">


<div id="org4b35a60" class="figure">
<p><img src="./fig/data_ventes_ex.png" alt="Data ventes ex" height="100%" />
</p>
</div>

</div>

<div class="column" style="float:right; width: 50%">

<div class="block-example" id="orgafc282f">
<p>
<h4>Caractéristiques des données</h4>
</p>

<ul>
<li>Nombre de variables : 3</li>
<li>Nombre d'individus : 14</li>
<li>Variable Âge à valeurs dans \(\set{[18,25] ; [26, 59] ; 60+}\)</li>
<li>Variable Épargne à valeurs dans \(\set{\text{non}, \text{oui}}\)</li>
<li>Variable Vente livret à valeurs dans \(\set{\text{échec}, \text{succès}}\)</li>

</ul>

</div>

</div>

</section>
</section>
<section>
<section id="slide-orgf3c356e">
<h3 id="orgf3c356e">Rappels statistiques</h3>
<p>
<div class="slidesubtitle">Modélisation statistique : objectifs et démarche</div>
</p>

<div class="block-definition" id="orgab0fb5c">
<p>
<h4>Objectifs</h4>
</p>

<ol>
<li>Résumer quantitativement l'information contenue dans des données en utilisant un modèle probabiliste</li>
<li>Exploiter le modèle pour déduire de nouvelles connaissances</li>

</ol>

</div>

<div class="block-definition" id="orge1b2c5a">
<p>
<h4>Démarche</h4>
</p>

<ul>
<li>Considérer les données comme des réalisations de variables aléatoires (v.a.) associées à une
certaine loi jointe</li>
<li>Formellement, cela signifie que chaque observation \(\mbf{x}_{n, \cdot} = \lrPar{x_{n,1}, \ldots,
  x_{n,D}}\) est supposée être une réalisation d'une suite de v.a. \(\mbf{X} =
  \lrPar{X_{1},\ldots,X_{D}}\) de loi jointe \(\mathcal{L}\lrPar{\mbf{\theta}}\) où \(\mbf{\theta}\)
représente les paramètres de la loi</li>
<li>Notation : \(\mbf{X} = \lrPar{X_{1},\ldots,X_{D}} \sim \mathcal{L}\lrPar{\mbf{\theta}}\)</li>

</ul>

</div>

</section>
</section>
<section>
<section id="slide-org3e83ad3">
<h3 id="org3e83ad3">Rappels statistiques</h3>
<p>
<div class="slidesubtitle">Modélisation statistique : remarques et exemple</div>
</p>

<div class="block-example" id="org6f4cd5d">
<p>
<h4>Remarques</h4>
</p>

<ul>
<li>Si les observations dans les données sont indépendantes, on parle de données i.i.d. (Indépendantes
et Identiquement Distribuées)</li>
<li>Si les caractéristiques (variables) des observations sont indépendantes, alors chaque variable \(X_{d}\) suit une loi \(\mathcal{L}_{d}\lrpar{\mbf{\theta}_{d}}\) (Notation : \(X_{d} \sim \mathcal{L}_{d}\lrpar{\mbf{\theta}_{d}}\))</li>

</ul>

</div>


<div class="block-example" id="orgae7c9b7">
<p>
<h4>Modèle gaussien</h4>
</p>

<ul>
<li>Données unidimensionnelles (\(D = 1\))
<ul>
<li>\(\mbf{X} = X_{1} \sim \mathcal{N}\lrPar{\mu, \sigma}\)</li>
<li>\(\mbf{\theta} = (\mu,\sigma)\) : moyenne et écart-type</li>

</ul></li>
<li>Données multidimensionnelles (\(D \ge 1\))
<ul>
<li>\(\mbf{X} = \lrPar{X_{1},\ldots,X_{D}} \sim \mathcal{N}\lrPar{\mbf{\mu}, \mbf{\Sigma}}\)</li>
<li>\(\mbf{\theta} = (\mbf{\mu},\mbf{\Sigma})\) : vecteur des moyennes et matrice de
variance-covariance</li>

</ul></li>

</ul>

</div>


</section>
</section>
<section>
<section id="slide-org1b3364e">
<h3 id="org1b3364e">Rappels statistiques</h3>
<p>
<div class="slidesubtitle">Estimation des paramètres d'un modèle</div>
</p>

<div class="block-definition" id="org3e084df">
<p>
<h4>Contexte</h4>
</p>

<ul>
<li>Données : On dispose de données \(\mathcal{D} = \lrpar{\mbf{x}_{1,\cdot}, \ldots,
  \mbf{x}_{N,\cdot}}\) où chaque observation \(\mbf{x}_{n,\cdot}\) est caractérisée par \(D\) variables \(\lrPar{x_{n,1},\ldots,x_{n,D}}\)</li>
<li>Modélisation : On suppose que \(\mathcal{D}\) est une suite de \(N\) réalisations i.i.d. du vecteur
aléatoire \(\mbf{X} = \lrpar{X_{1}, \ldots, X_{D}}\) distribué selon la loi \(\mathcal{L}\lrPar{\mbf{\theta}}\)</li>
<li><b>Problématique :</b> Comment estimer les paramètres \(\mbf{\theta}\) à partir des données \(\mathcal{D}\)?</li>

</ul>

</div>


<div class="block-definition" id="orgc93d452">
<p>
<h4>Solution</h4>
</p>

<ul>
<li>Construire un estimateur de \(\mbf{\theta}\)</li>
<li>Approche classique : Déterminer l'estimateur du maximum de <b>vraisemblance</b> de \(\mbf{\theta}\),
souvent noté \(\mbf{\theta}^{\text{MV}}\)</li>

</ul>

</div>



</section>
</section>
<section>
<section id="slide-org7ec13e5">
<h3 id="org7ec13e5">Rappels statistiques</h3>
<p>
<div class="slidesubtitle">Notion de vraisemblance</div>
</p>

<div class="block-definition" id="org9ef675f">
<p>
<h4>Vraisemblance d'un modèle par rapport à une observation</h4>
</p>

<ul>
<li>Soit \(\mathcal{D} = \lrpar{\mbf{x}_{1,\cdot}, \ldots, \mbf{x}_{N,\cdot}}\) un ensemble de données
i.i.d. modélisées par les v.a. \(\mbf{X} = \lrpar{X_{1}, \ldots, X_{D}} \sim \mathcal{L}\lrPar{\mbf{\theta}}\)</li>
<li>La vraisemblance mesure la plausibilité d'un modèle probabiliste (caractérisé par un ensemble de paramètres
\(\mbf{\theta}\)) par rapport à l'observation \(\mbf{x}_{n,\cdot} \in \mathcal{D}\)
<ul>
<li>La vraisemblance est notée \(L\lrPar{\mbf{\theta};\mbf{x}_{n,\cdot}}\)</li>

</ul></li>
<li>En pratique le logarithme de la vraisemblance est souvent utilisé, on parle alors de
log-vraisemblance \(\ell\lrPar{\mbf{\theta};\mbf{x}_{n,\cdot}} = \ln
  L\lrPar{\mbf{\theta};\mbf{x}_{n,\cdot}}\)</li>

</ul>

</div>


<div class="block-example" id="org686b7d3">
<p>
<h4>Interprétation</h4>
</p>

<ul>
<li>une vraisemblance <b>élevée</b> signifie que le modèle choisi est <b>crédible</b> par rapport
à la donnée observée</li>
<li>une vraisemblance <b>faible</b> signifie que le modèle choisi est <b>peu crédible</b> par
rapport à la donnée observée</li>

</ul>

</div>

</section>
<section id="slide-orgd26a6d1">
<h4 id="orgd26a6d1">Rappels statistiques</h4>
<p>
<div class="slidesubtitle">Notion de vraisemblance</div>
</p>

<div class="block-definition" id="org08ce558">
<p>
<h4>Vraisemblance d'un modèle discret et fini par rapport à une observation</h4>
</p>

<ul>
<li>Si les v.a. \(\mbf{X} = \lrpar{X_{1}, \ldots, X_{D}}\) sont discrètes et finies, alors la
vraisemblance du modèle \(\Prob\lrPar{X_{1},\ldots, X_{D}}\) sachant l'observation
\(\mbf{x}_{n,\cdot}\) est donnée par :
\[
  L\lrPar{\Prob;\mbf{x}_{n,\cdot}} = \Prob\lrPar{X_{1} = x_{n,1},\ldots, X_{D} = x_{n,D}}, \quad
  \text{(ici } \mbf{\theta} = \Prob \text{)}
  \]</li>

</ul>

</div>

<div class="column" style="float:left; width: 60%">

<div class="block-example" id="orga34e3b7">
<p>
<h4>Exemple : vraisemblance d'une observation</h4>
</p>

<ul>
<li>Considérons la loi jointe ci-contre pour représenter le processus de vente d'un livret A :</li>

<li>Observation :
<ul>
<li>Âge : [26,59]</li>
<li>Épargne : non</li>
<li>Vente livret A : échec</li>

</ul></li>

<li>Vraisemblance = 0.12</li>
<li>Log-vraisemblance \(\simeq\) -2.12</li>

</ul>

</div>

</div>

<div class="column" style="float:right; width: 40%">


<div id="orga675295" class="figure">
<p><img src="./fig/lj_vente_ex_hi_indiv.png" alt="Data ventes ex" height="100%" />
</p>
</div>

</div>

</section>
<section id="slide-orgb16e62a">
<h4 id="orgb16e62a">Rappels statistiques</h4>
<p>
<div class="slidesubtitle">Notion de vraisemblance</div>
</p>

<div class="block-definition" id="org2aa3c48">
<p>
<h4>Vraisemblance d'un modèle par rapport à des données</h4>
</p>

<ul>
<li>La vraisemblance d'un modèle (paramétré par \(\mbf{\theta}\)) par rapport à des données
\(\mathcal{D}\), notée \(L\lrPar{\mbf{\theta};\mathcal{D}}\), correspond à la plausibilité du modèle
\(\mbf{\theta}\) par rapport à l'observation des données \(\mathcal{D}\)</li>
<li>Lorsque les données sont supposées i.i.d., la vraisemblance est définie par
\[
  L\lrPar{\mbf{\theta};\mathcal{D}} = \prod_{n = 1}^{N} L\lrPar{\mbf{\theta};\mbf{x}_{n,\cdot}}
  \]</li>
<li><p>
Lorsque l'on s'intéresse à des données, on utilise souvent la log-vraisemblance qui est
définie par : 
</p>
<div>
\begin{align*}
\ell\lrPar{\mbf{\theta};\mathcal{D}} & = \ln L\lrPar{\mbf{\theta};\mathcal{D}} \\
& = \sum_{n = 1}^{N}
\ln L\lrPar{\mbf{\theta};\mbf{x}_{n,\cdot}} \\
& = \sum_{n = 1}^{N}
\ell\lrPar{\mbf{\theta};\mbf{x}_{n,\cdot}}
\end{align*}

</div></li>

</ul>

</div>

</section>
<section id="slide-orgdc874d4">
<h4 id="orgdc874d4">Rappels statistiques</h4>
<p>
<div class="slidesubtitle">Notion de vraisemblance</div>
</p>

<div class="block-example" id="orgf439fa2">
<p>
<h4>Interprétation de la vraisemblance</h4>
</p>
<ul>
<li>La vraisemblance est un indicateur permettant de comparer la pertinence de différents modèles
probabilistes en les confrontant aux données observées</li>
<li>La vraisemblance ne peut être utilisée pour évaluer un modèle de manière isolée</li>
<li>Dans l'absolu plus la log-vraisemblance d'un modèle par rapport à des \(\mathcal{D}\) est élevée,
plus le modèle probabiliste considéré est adapté pour représenter le phénomène sous-jacent</li>

</ul>

</div>

<div class="block-alert" id="org8be2790">
<p>
<h4>Attention !</h4>
</p>
<ul>
<li>La vraisemblance décroît avec le nombre de données observées, donc :
<ul>
<li>Il n'est pas pertinent de comparer des vraisemblances obtenues à partir de jeux de données de
taille différente</li>
<li>En revanche, il peut être intéressant de comparer des vraisemblances moyennes par donnée
observée</li>

</ul></li>

</ul>

</div>

</section>
<section id="slide-orgf17fbdf">
<h4 id="orgf17fbdf">Rappels statistiques</h4>
<p>
<div class="slidesubtitle">Notion de vraisemblance</div>
</p>

<div class="block-example" id="org28fba2b">
<p>
<h4>Exemple : vraisemblance d'un modèle par rapport à des données</h4>
</p>
<ul>
<li>Données : 3 individus définis par 3 variables</li>
<li>Modèle : une loi jointe sur les variables caractérisant les individus</li>

</ul>

</div>


<div class="column" style="float:left; width: 40%">
<p>
<b>Modèle probabiliste</b>
</p>

<div id="orga857586" class="figure">
<p><img src="./fig/lj_vente_ex.png" alt="Data ventes ex" height="100%" />
</p>
</div>
</div>

<div class="column" style="float:right; width: 50%">
<p>
<b>Données</b>
</p>

<div id="org842f7ba" class="figure">
<p><img src="./fig/vente_3var_ex_like.png" alt="Data ventes ex" height="100%" />
</p>
</div>
</div>

</section>
<section id="slide-orgd465ccf">
<h4 id="orgd465ccf">Rappels statistiques</h4>
<p>
<div class="slidesubtitle">Notion de vraisemblance</div>
</p>

<div class="block-example" id="org5c3659d">
<p>
<h4>Exemple : vraisemblance d'un modèle par rapport à des données</h4>
</p>
<ul>
<li>Données : 3 individus définis par 3 variables</li>
<li>Modèle : une loi jointe sur les variables caractérisant les individus</li>

</ul>

</div>


<div class="column" style="float:left; width: 40%">
<p>
<b>Modèle probabiliste</b>
</p>

<div id="org25cc4a4" class="figure">
<p><img src="./fig/lj_vente_ex_like_hi_1.png" alt="Data ventes ex" height="100%" />
</p>
</div>
</div>

<div class="column" style="float:right; width: 50%">
<p>
<b>Données</b>
</p>

<div id="org0f07ad6" class="figure">
<p><img src="./fig/vente_3var_ex_like_hi1.png" alt="Data ventes ex" height="100%" />
</p>
</div>
</div>

</section>
<section id="slide-org1fd6682">
<h4 id="org1fd6682">Rappels statistiques</h4>
<p>
<div class="slidesubtitle">Notion de vraisemblance</div>
</p>

<div class="block-example" id="org3ea1a22">
<p>
<h4>Exemple : vraisemblance d'un modèle par rapport à des données</h4>
</p>
<ul>
<li>Données : 3 individus définis par 3 variables</li>
<li>Modèle : une loi jointe sur les variables caractérisant les individus</li>

</ul>

</div>


<div class="column" style="float:left; width: 40%">
<p>
<b>Modèle probabiliste</b>
</p>

<div id="orgdd519eb" class="figure">
<p><img src="./fig/lj_vente_ex_like_hi_2.png" alt="Data ventes ex" height="100%" />
</p>
</div>
</div>

<div class="column" style="float:right; width: 50%">
<p>
<b>Données</b>
</p>

<div id="org921ccda" class="figure">
<p><img src="./fig/vente_3var_ex_like_hi2.png" alt="Data ventes ex" height="100%" />
</p>
</div>
</div>

</section>
<section id="slide-orgbbd4603">
<h4 id="orgbbd4603">Rappels statistiques</h4>
<p>
<div class="slidesubtitle">Notion de vraisemblance</div>
</p>

<div class="block-example" id="org89b26a5">
<p>
<h4>Exemple : vraisemblance d'un modèle par rapport à des données</h4>
</p>
<ul>
<li>Données : 3 individus définis par 3 variables</li>
<li>Modèle : une loi jointe sur les variables caractérisant les individus</li>

</ul>

</div>


<div class="column" style="float:left; width: 40%">
<p>
<b>Modèle probabiliste</b>
</p>

<div id="org8256feb" class="figure">
<p><img src="./fig/lj_vente_ex_like_hi_3.png" alt="Data ventes ex" height="100%" />
</p>
</div>
</div>

<div class="column" style="float:right; width: 50%">
<p>
<b>Données</b>
</p>

<div id="orgb19592e" class="figure">
<p><img src="./fig/vente_3var_ex_like_hi3.png" alt="Data ventes ex" height="100%" />
</p>
</div>
</div>

</section>
<section id="slide-org91c235f">
<h4 id="org91c235f">Rappels statistiques</h4>
<p>
<div class="slidesubtitle">Notion de vraisemblance</div>
</p>

<div class="block-example" id="org2fa7875">
<p>
<h4>Exemple : vraisemblance d'un modèle par rapport à des données</h4>
</p>
<ul>
<li>Données : 3 individus définis par 3 variables</li>
<li>Modèle : une loi jointe sur les variables caractérisant les individus</li>

</ul>

</div>


<div class="column" style="float:left; width: 40%">
<p>
<b>Modèle probabiliste</b>
</p>

<div id="org9e89a84" class="figure">
<p><img src="./fig/lj_vente_ex.png" alt="Data ventes ex" height="100%" />
</p>
</div>
</div>

<div class="column" style="float:right; width: 50%">
<p>
<b>Données</b>
</p>

<div id="org51e7821" class="figure">
<p><img src="./fig/vente_3var_ex_like_value.png" alt="Data ventes ex" height="100%" />
</p>
</div>
</div>

</section>
</section>
<section>
<section id="slide-org22af786">
<h3 id="org22af786">Rappels statistiques</h3>
<p>
<div class="slidesubtitle">Estimateur du maximum de vraisemblance</div>
</p>

<div class="block-definition" id="org6a66736">
<p>
<h4>Estimateur du maximum de vraisemblance</h4>
</p>
<ul>
<li>Soit \(\mathcal{D} = \lrpar{\mbf{x}_{1,\cdot}, \ldots, \mbf{x}_{N,\cdot}}\) un ensemble de données
supposées i.i.d. modélisées par les v.a. \(\mbf{X} = \lrpar{X_{1}, \ldots, X_{D}} \sim
  \mathcal{L}\lrPar{\mbf{\theta}}\)</li>
<li>On dit que \(\mbf{\theta}^{\text{MV}}\) est un estimateur du maximum de vraisemblance (EMV) de
\(\mbf{\theta}\) si \(\mbf{\theta}^{\text{MV}}\) maximise la vraisemblance, c-à-d.  
\[
  \mbf{\theta}^{\text{MV}} = \argmax{\mbf{\theta}} L\lrPar{\mbf{\theta};\mathcal{D}}
  \]</li>

</ul>

</div>

<div class="block-definition" id="orgb4e7cd5">
<p>
<h4>Propriétés des estimateurs du maximum de vraisemblance</h4>
</p>
<ul>
<li><b>Convergents en probabilité</b> vers les paramètres à estimer</li>
<li><b>Efficaces</b>, c'est-à-dire qu'ils convergent rapidement</li>
<li><b>Asymptotiquement normaux</b>, c'est-à-dire qu'il est facile de construire des intervalles de confiance
sur les estimations obtenues</li>

</ul>

</div>

</section>
</section>
<section>
<section id="slide-orgd25ebe1">
<h2 id="orgd25ebe1">Apprentissage des LPC - Données complètes</h2>

<div id="orgb31247f" class="figure">
<p><img src="./fig/learning_data_complete.png" alt="Inférence" width="60%" />
</p>
</div>

</section>
</section>
<section>
<section id="slide-org7cbd841">
<h3 id="org7cbd841">Apprentissage des LPC - Données complètes</h3>
<p>
<div class="slidesubtitle">Hypothèses</div>
</p>

<div class="block-definition" id="orgadc1f07">
<p>
<h4>Hypothèses</h4>
</p>
<ul>
<li>On modélise un phénomène aléatoire caractérisé par des variables aléatoires \(X_{1}, \ldots, X_{D}\)
dont la loi est représentée par un RB</li>
<li>Les variables aléatoires \(X_{1}, \ldots, X_{D}\) sont discrètes et finies</li>
<li>Le graphe du RB est supposé connu</li>
<li>On dispose d'un jeu de données \(\boldsymbol{D} = (\boldsymbol{x}_{1}, \ldots, \boldsymbol{x}_{N})\)
où chaque observation \(\boldsymbol{x}_{n}\) est caractérisée par \(D\) variables \((x_{n,1},\ldots,x_{n,D})\)</li>

</ul>

</div>

<div class="block-definition" id="orgd41fc0e">
<p>
<h4>Objectif</h4>
</p>

<ul>
<li>On suppose que \(\mathcal{D}\) est une suite de \(N\) réalisations i.i.d. du
vecteur aléatoire discret et fini \(\mbf{X} = \lrpar{X_{1}, \ldots, X_{D}}\) dont la loi est représentée par un RB \(\mathcal{M}\)
défini par ses LPC</li>
<li>On cherche à estimer les LPC de ce RB (car la structure est supposée connue),
autrement dit :
\[
  \mbf{\theta} = \lrPar{\Prob\lrPar{X_{1}|\pa\lrPar{X_{1}}}, \ldots,
  \Prob\lrPar{X_{D}|\pa\lrPar{X_{D}}}}
  \]</li>
<li>Notation alternative : \(\mbf{\theta} = \lrPar{\theta_{1}, \ldots, \theta_{d}, \ldots, \theta_{D}}\)
avec \(\theta_{d} = \Prob\lrPar{X_{d}|\pa\lrPar{X_{d}}}\)</li>

</ul>

</div>


</section>
</section>
<section>
<section id="slide-org67569de">
<h3 id="org67569de">Apprentissage des LPC - Données complètes</h3>
<p>
<div class="slidesubtitle">Exemple</div>
</p>


<div id="org198d478" class="figure">
<p><img src="./fig/rb_vente_lpc_app_mod.png" alt="LPC app" width="100%" />
</p>
</div>

</section>
<section id="slide-orgc06f303">
<h4 id="orgc06f303">Apprentissage des LPC - Données complètes</h4>
<p>
<div class="slidesubtitle">Exemple</div>
</p>


<div id="org6839dbe" class="figure">
<p><img src="./fig/rb_vente_lpc_app_ex1.png" alt="LPC app" width="100%" />
</p>
</div>

</section>
<section id="slide-org0e4b557">
<h4 id="org0e4b557">Apprentissage des LPC - Données complètes</h4>
<p>
<div class="slidesubtitle">Exemple</div>
</p>


<div id="org104e9d7" class="figure">
<p><img src="./fig/rb_vente_lpc_app_ex2.png" alt="LPC app" width="100%" />
</p>
</div>

</section>
<section id="slide-orgb4cc40e">
<h4 id="orgb4cc40e">Apprentissage des LPC - Données complètes</h4>
<p>
<div class="slidesubtitle">Exemple</div>
</p>


<div id="orgd40ee50" class="figure">
<p><img src="./fig/rb_vente_lpc_app_ex3.png" alt="LPC app" width="100%" />
</p>
</div>

</section>
<section id="slide-orgaccd46e">
<h4 id="orgaccd46e">Apprentissage des LPC - Données complètes</h4>
<p>
<div class="slidesubtitle">Exemple</div>
</p>


<div id="org32b12e0" class="figure">
<p><img src="./fig/rb_vente_lpc_app_ex4.png" alt="LPC app" width="100%" />
</p>
</div>

</section>
<section id="slide-org3f0b5fe">
<h4 id="org3f0b5fe">Apprentissage des LPC - Données complètes</h4>
<p>
<div class="slidesubtitle">Exemple</div>
</p>


<div id="org9fcda2d" class="figure">
<p><img src="./fig/rb_vente_lpc_app_ex5.png" alt="LPC app" width="100%" />
</p>
</div>

</section>
<section id="slide-org78da403">
<h4 id="org78da403">Apprentissage des LPC - Données complètes</h4>
<p>
<div class="slidesubtitle">Exemple</div>
</p>


<div id="orgfdf00ef" class="figure">
<p><img src="./fig/rb_vente_lpc_app_ex6.png" alt="LPC app" width="100%" />
</p>
</div>

</section>
<section id="slide-org23a03af">
<h4 id="org23a03af">Apprentissage des LPC - Données complètes</h4>
<p>
<div class="slidesubtitle">Exemple</div>
</p>


<div id="orge9ac82b" class="figure">
<p><img src="./fig/rb_vente_lpc_app_ex7.png" alt="LPC app" width="100%" />
</p>
</div>

</section>
<section id="slide-org51c28a5">
<h4 id="org51c28a5">Apprentissage des LPC - Données complètes</h4>
<p>
<div class="slidesubtitle">Exemple</div>
</p>


<div id="org8cbf7b5" class="figure">
<p><img src="./fig/rb_vente_lpc_app_ex8.png" alt="LPC app" width="100%" />
</p>
</div>


</section>
</section>
<section>
<section id="slide-org0b17ea9">
<h3 id="org0b17ea9">Apprentissage des LPC - Données complètes</h3>
<p>
<div class="slidesubtitle">Méthode du maximum de vraisemblance dans un RB</div>
</p>

<div class="block-definition" id="org2311f73">
<p>
<h4>Méthode du maximum de vraisemblance</h4>
</p>
<ul>
<li><p>
La vraisemblance d'un RB \(\mathcal{M}\lrPar{\theta_{1},\ldots,\theta_{D}}\) par rapport aux données
\(\mathcal{D} = (\boldsymbol{x}_{1}, \ldots, \boldsymbol{x}_{N})\) i.i.d. est définie par 
</p>
<div>
\begin{align*}
  L\lrPar{\theta_{1},\ldots,\theta_{D};\mathcal{D}} & = \prod_{n = 1}^{N} L\lrPar{\theta_{1},\ldots,\theta_{D};\mbf{x}_{n,\cdot}} \\
  & = \prod_{n = 1}^{N} \prod_{d = 1}^{D} \Prob\lrPar{X_{d}
    = x_{n,d}|\pa\lrPar{X_{d}} = \pa\lrPar{x_{n,d}}}
\end{align*}

</div></li>
<li>D'où la log-vraisemblance :
\[
  \ell\lrPar{\theta_{1},\ldots,\theta_{D};\mathcal{D}} = \sum_{n =
  1}^{N} \sum_{d = 1}^{D} \ln \Prob\lrPar{X_{d} = x_{n,d}|\pa\lrPar{X_{d}} = \pa\lrPar{x_{n,d}}}
  \]</li>
<li><b>Objectif :</b> Trouver \(\theta_{1},\ldots,\theta_{D}\) tels que
\(\ell\lrPar{\theta_{1},\ldots,\theta_{D};\mathcal{D}}\) soit maximum, c-à-d, résoudre le problème
d'optimisation :
\[
  \theta_{1}^{\text{MV}} ,\ldots,\theta_{D}^{\text{MV}} = \argmax{\theta_{1},\ldots,\theta_{D}} \ell\lrPar{\theta_{1},\ldots,\theta_{D};\mathcal{D}}  
  \]</li>

</ul>

</div>

</section>
</section>
<section>
<section id="slide-org5d7b50e">
<h3 id="org5d7b50e">Apprentissage des LPC - Données complètes</h3>
<p>
<div class="slidesubtitle">Estimateur du maximum de vraisemblance dans un RB</div>
</p>

<div class="block-definition" id="orge7978d4">
<p>
<h4>Estimateur du maximum de vraisemblance</h4>
</p>

<ul>
<li>L'estimation du maximum de vraisemblance de chaque LPC d'un RB a pour expression :
\[
  \hat{P}^{\text{MV}}(X_{d} = x_{d,k}|\text{pa}(X_{d}) = \boldsymbol{x}^{\prime}_{d,j}) =
  \frac{\# \{X_{d} = x_{d,k}~ \text{et}~
      \text{pa}(X_{d}) = \boldsymbol{x}^{\prime}_{d,j}\}}{\# \{\text{pa}(X_{d}) = \boldsymbol{x}^{\prime}_{d,j}\}}
  \]
<ul>
<li>\(x_{d,k}\) : \(k\) -ème valeur possible pour la v.a. \(X_{d}\)</li>
<li>\(\boldsymbol{x}^{\prime}_{d,j}\) : \(j\) -ème configuration de valeurs possibles pour les parents de la
v.a. \(X_{d}\)</li>

</ul></li>

<li><b>Interprétation :</b>
<ul>
<li>Chaque probabilité \(\hat{P}^{\text{MV}}(X_{d} = x_{d,k}|\text{pa}(X_{d}) =
    \boldsymbol{x}^{\prime}_{d,j})\) est estimée par le rapport entre : 
<ul>
<li>le nombre d'événements \(\{X_{d} = x_{d,k}~ \text{et}~
      \text{pa}(X_{d}) = \boldsymbol{x}^{\prime}_{d,j}\}\) observés dans les données</li>
<li>et le nombre d'événements \(\{\text{pa}(X_{d}) = \boldsymbol{x}^{\prime}_{d,j}\}\) observés dans les données</li>

</ul></li>

</ul></li>

</ul>

</div>


</section>
</section>
<section>
<section id="slide-org8a0bd0a">
<h2 id="org8a0bd0a">Apprentissage des LPC - Données incomplètes</h2>

<div id="org852ecda" class="figure">
<p><img src="./fig/learning_data_missing.png" alt="Learning" width="60%" />
</p>
</div>

</section>
</section>
<section>
<section id="slide-org2b15b06">
<h3 id="org2b15b06">Apprentissage des LPC - Données incomplètes</h3>
<p>
<div class="slidesubtitle">Représentation des données</div>
</p>


<div id="org87cd0a4" class="figure">
<p><img src="./fig/vente_livret_ex.png" alt="Data ventes" width="75%" />
</p>
</div>

<div class="block-definition" id="org8241312">
<p>
<h4>Représentation classique</h4>
</p>
<ul>
<li>Les observations de chaque variable sont données explicitement</li>
<li>Représentation intuitive mais peu adaptée aux traitements des données incomplète</li>

</ul>

</div>

</section>
<section id="slide-org06d2b60">
<h4 id="org06d2b60">Apprentissage des LPC - Données incomplètes</h4>
<p>
<div class="slidesubtitle">Représentation des données</div>
</p>


<div id="orgfadddb3" class="figure">
<p><img src="./fig/vente_livret_disj_ex.png" alt="Data ventes disjonctive" width="75%" />
</p>
</div>

<div class="block-definition" id="org4f10e8c">
<p>
<h4>Représentation disjonctive (one-hot encoding)</h4>
</p>
<ul>
<li>Chaque variable \(X\) possédant \(K\) modalités est décomposée en \(K\) sous-variables binaires où la
modalité prise est associée à la valeur 1</li>
<li>Représentation plus complexe mais adaptée aux traitements des différents types de données incomplètes</li>

</ul>

</div>


</section>
</section>
<section>
<section id="slide-org891549e">
<h3 id="org891549e">Apprentissage des LPC - Données incomplètes</h3>
<p>
<div class="slidesubtitle">Données manquantes</div>
</p>


<div id="orgda803cb" class="figure">
<p><img src="./fig/vente_livret_ex_missing_data_classic.png" alt="Data ventes disjonctive" width="100%" />
</p>
</div>

</section>
<section id="slide-orgb62aac9">
<h4 id="orgb62aac9">Apprentissage des LPC - Données incomplètes</h4>
<p>
<div class="slidesubtitle">Données manquantes (forme disjonctive)</div>
</p>


<div id="org4a32b64" class="figure">
<p><img src="./fig/vente_livret_ex_missing_data_classic_disj.png" alt="Data ventes disjonctive" width="100%" />
</p>
</div>


</section>
<section id="slide-org6c580a2">
<h4 id="org6c580a2">Apprentissage des LPC - Données incomplètes</h4>
<p>
<div class="slidesubtitle">Données partiellement observées</div>
</p>


<div id="orgec07d7c" class="figure">
<p><img src="./fig/vente_livret_ex_missing_data_partial_disj.png" alt="Data ventes disjonctive" width="100%" />
</p>
</div>

</section>
<section id="slide-orga2cb70f">
<h4 id="orga2cb70f">Apprentissage des LPC - Données incomplètes</h4>
<p>
<div class="slidesubtitle">Données pondérées</div>
</p>


<div id="org7247237" class="figure">
<p><img src="./fig/vente_livret_ex_missing_data_weighted_disj.png" alt="Data ventes disjonctive" width="100%" />
</p>
</div>


</section>
</section>
<section>
<section id="slide-orgfeb675f">
<h3 id="orgfeb675f">Apprentissage des LPC - Données incomplètes</h3>
<p>
<div class="slidesubtitle">Algorithme Expectation-Maximisation (EM)</div>
</p>

<div class="block-definition" id="org23d7374">
<p>
<h4>Principes de l'algorithme EM</h4>
</p>
<ul>
<li>Algorithme initialement développé par (Dempster, A. and Laird, N. and Rubin, D. B., 1977)</li>
<li>Ensemble d'algorithmes d'optimisation itératifs</li>
<li>Décomposition d'un problème d'optimisation complexe en deux sous problèmes d'optimisation
alternés plus simples</li>

</ul>

</div>

<div class="block-example" id="org88a66fd">
<p>
<h4>Application en statistiques</h4>
</p>
<ul>
<li>Calculer les estimations des paramètres d'un modèle probabiliste par la méthode du maximum de
vraisemblance en présence de données incomplètes</li>

</ul>

</div>

<div class="block-definition" id="orgaff74a2">
<p>
<h4>Propriété</h4>
</p>
<ul>
<li>Méthode d'optimisation locale</li>
<li>La convergence vers l'optimum global n'est pas garantie</li>
<li>La qualité de la solution calculée dépend de l'initialisation de l'algorithme</li>

</ul>

</div>

</section>
</section>
<section>
<section id="slide-org07d9abc">
<h3 id="org07d9abc">Apprentissage des LPC - Données incomplètes</h3>
<p>
<div class="slidesubtitle">Algorithme EM dans les RB - Exemple</div>
</p>

<div class="block-definition" id="org8c21d84">
<p>
<h4>Contexte</h4>
</p>

<ul>
<li>Données disponibles \(\mathcal{D} = \mathcal{D}_{\text{C}} \union \mathcal{D}_{\text{I}}\) :
<ul>
<li>\(\mathcal{D}_{\text{C}}\) : Observations complètement observées</li>
<li>\(\mathcal{D}_{\text{I}}\) : Observations partiellement observées</li>

</ul></li>
<li>Modélisation : \(\mathcal{D} =\) réalisations i.i.d. de la suite de v.a. \(\mbf{X} =
  \lrpar{X_{1}, \ldots, X_{D}}\) représenté par un RB \(\mathcal{M}\) de structure supposée connue</li>

</ul>

</div>


<div id="orgceba2b7" class="figure">
<p><img src="./fig/em_rb_vente_livret_contexte.png" alt="Data ventes disjonctive" width="70%" />
</p>
</div>


</section>
<section id="slide-org2982897">
<h4 id="org2982897">Apprentissage des LPC - Données incomplètes</h4>
<p>
<div class="slidesubtitle">Algorithme EM dans les RB - Exemple</div>
</p>


<div id="orgeddfc86" class="figure">
<p><img src="./fig/em_rb_vente_livret_contexte.png" alt="Data ventes disjonctive" width="100%" />
</p>
</div>

</section>
<section id="slide-orgb2d6056">
<h4 id="orgb2d6056">Apprentissage des LPC - Données incomplètes</h4>
<p>
<div class="slidesubtitle">Algorithme EM dans les RB - Exemple</div>
</p>


<div id="org2e34a13" class="figure">
<p><img src="./fig/em_rb_vente_livret_setup.png" alt="Data ventes disjonctive" width="100%" />
</p>
</div>

</section>
<section id="slide-org7fb9718">
<h4 id="org7fb9718">Apprentissage des LPC - Données incomplètes</h4>
<p>
<div class="slidesubtitle">Algorithme EM dans les RB - Exemple</div>
</p>


<div id="org0720545" class="figure">
<p><img src="./fig/em_rb_vente_livret_0.png" alt="Data ventes disjonctive" width="100%" />
</p>
</div>

</section>
<section id="slide-orgce34766">
<h4 id="orgce34766">Apprentissage des LPC - Données incomplètes</h4>
<p>
<div class="slidesubtitle">Algorithme EM dans les RB - Exemple</div>
</p>


<div id="orga41beec" class="figure">
<p><img src="./fig/em_rb_vente_livret_1_E.png" alt="Data ventes disjonctive" width="100%" />
</p>
</div>


</section>
<section id="slide-org5d9842d">
<h4 id="org5d9842d">Apprentissage des LPC - Données incomplètes</h4>
<p>
<div class="slidesubtitle">Algorithme EM dans les RB - Exemple</div>
</p>


<div id="orga9ca2b3" class="figure">
<p><img src="./fig/em_rb_vente_livret_1_M.png" alt="Data ventes disjonctive" width="100%" />
</p>
</div>


</section>
<section id="slide-org52512db">
<h4 id="org52512db">Apprentissage des LPC - Données incomplètes</h4>
<p>
<div class="slidesubtitle">Algorithme EM dans les RB - Exemple</div>
</p>


<div id="org71e1588" class="figure">
<p><img src="./fig/em_rb_vente_livret_1_M_bis.png" alt="Data ventes disjonctive" width="100%" />
</p>
</div>


</section>
<section id="slide-org67316c7">
<h4 id="org67316c7">Apprentissage des LPC - Données incomplètes</h4>
<p>
<div class="slidesubtitle">Algorithme EM dans les RB - Exemple</div>
</p>


<div id="org9a2d25a" class="figure">
<p><img src="./fig/em_rb_vente_livret_2_E.png" alt="Data ventes disjonctive" width="100%" />
</p>
</div>


</section>
<section id="slide-org502265e">
<h4 id="org502265e">Apprentissage des LPC - Données incomplètes</h4>
<p>
<div class="slidesubtitle">Algorithme EM dans les RB - Exemple</div>
</p>


<div id="org2b2ee39" class="figure">
<p><img src="./fig/em_rb_vente_livret_2_M.png" alt="Data ventes disjonctive" width="100%" />
</p>
</div>


</section>
<section id="slide-org72b210d">
<h4 id="org72b210d">Apprentissage des LPC - Données incomplètes</h4>
<p>
<div class="slidesubtitle">Algorithme EM dans les RB - Exemple</div>
</p>


<div id="org88d0797" class="figure">
<p><img src="./fig/em_rb_vente_livret_3_E.png" alt="Data ventes disjonctive" width="100%" />
</p>
</div>


</section>
<section id="slide-org79d9b21">
<h4 id="org79d9b21">Apprentissage des LPC - Données incomplètes</h4>
<p>
<div class="slidesubtitle">Algorithme EM dans les RB - Exemple</div>
</p>


<div id="org81b04f9" class="figure">
<p><img src="./fig/em_rb_vente_livret_3_E_bis.png" alt="Data ventes disjonctive" width="100%" />
</p>
</div>

</section>
<section id="slide-orgec0a6be">
<h4 id="orgec0a6be">Apprentissage des LPC - Données incomplètes</h4>
<p>
<div class="slidesubtitle">Algorithme EM dans les RB</div>
</p>

<div class="block-definition" id="org6e34a0b">
<p>
<h4>Algorithme EM dans les RB (structure connue)</h4>
</p>

<ul>
<li>Initialisation du modèle RB \(\mathcal{M}^{(0)}\) caractérisé par ses LPC</li>
<li><b>Étape E</b> : Estimer la loi des données manquantes à partir du RB courant, noté \(\mathcal{M}^{(t)}\)
<ul>
<li>Pour chaque donnée incomplète \(\mbf{x} = \lrpar{\mbf{x}_{\text{obs}},\mbf{x}_{\text{mqt}}} \in \mathcal{D}_{\text{I}}\)
<ul>
<li>Calculer la distribution de ses variables manquantes \(\mbf{X}_{\text{mqt}}\) conditionnellement à ses variables observées \(\mbf{X}_{\text{obs}}\)</li>
<li>Calculer \(\Prob\lrPar{\mbf{X}_{\text{obs}}|\mbf{X}_{\text{mqt}}}\) en utilisant un algorithme
d'inférence dans \(\mathcal{M}^{(t)}\)</li>

</ul></li>
<li>"Nouvelles" données courante \(\mathcal{D}^{(t+1)} = \mathcal{D}_{\text{C}} \union
    \mathcal{D}_{\text{I}}^{(t+1)}\) complétées par les distributions des variables manquantes</li>

</ul></li>
<li><b>Étape M</b> : Estimer les LPC du modèle \(\mathcal{M}^{(t+1)}\) à partir des données complétées
\(\mathcal{D}^{(t)}\) 
<ul>
<li>Utilisation de la méthode du maximum de vraisemblance</li>

</ul></li>
<li>Répéter les étapes E et M tant que \(\mathcal{M}^{(t)}\) et \(\mathcal{M}^{(t+1)}\) sont
significativement différents</li>

</ul>

</div>

</section>
</section>
<section>
<section id="slide-org28c43be">
<h2 id="org28c43be">Résumé de la séance</h2>
<div class="block-definition" id="orge4b01a0">
<p>
<h4>Points clés sur l'apprentissage des LPC</h4>
</p>

<ul>
<li>Rappels généraux sur l'apprentissage statistique</li>
<li>Formalisation du problème d'apprentissage des LPC du point de vue statistique</li>
<li>Mise en oeuvre de la méthode du maximum de vraisemblance pour estimer les LPC d'un RB</li>

</ul>

</div>

<div class="block-definition" id="org8ab197f">
<p>
<h4>Pour aller plus loin</h4>
</p>
<ul>
<li>Apprentissage des LPC dans le cas de données incomplètes</li>
<li>Apprentissage automatique de la structure d'un RB</li>

</ul>

</div>

</section>
</section>
<section>
<section id="slide-orgf11a2e0">
<h3 id="orgf11a2e0">Merci pour votre attention !</h3>
<p>
<div class="slidesubtitle">Des questions ?</div>
</p>



<div id="orge82ac35" class="figure">
<p><img src="https://roland-donat.github.io/cours-rb/commons/questions.png" alt="FAQ" width="60%" />
</p>
</div>


</section>
</section>
<section>
<section id="slide-orgb2b4606">
<h2 id="orgb2b4606">Bibliographie</h2>
<p>
Dempster, A. and Laird, N. and Rubin, D. B. (1977). <i>Maximum {Likelihood} from {Incomplete} {Data} {Via} the {EM} {Algorithm}</i>, Journal of the Royal Statistical Society.</p>
</section>
</section>
</div>
</div>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/dist/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({
controlsLayout: 'edges', slideNumber:"c/t", center: false, transition: 'fade',

// Optional libraries used to extend on reveal.js
dependencies: [
 { src: 'https://cdn.jsdelivr.net/npm/reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: 'https://cdn.jsdelivr.net/npm/reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: 'https://cdn.jsdelivr.net/npm/reveal.js/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
 { src: 'https://cdn.jsdelivr.net/npm/reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }]

});

</script>
</body>
</html>
